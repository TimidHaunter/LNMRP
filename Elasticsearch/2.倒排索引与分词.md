## Analyzer

分词器，分析器

Lucene：负责`倒排索引`物理构建

Analyzer：负责在建立倒排索引前和搜索前对文本进行`词法和语法`处理



## 倒排索引

正排索引：通过文档ID关联文档内容
倒排索引：通过关键单词关联ID



### 简单倒排索引

![简单的倒排例子](G:\data\LNMRP\$Image\ElasticSearch\es_invert_index.png)



### 复杂倒排索引

- 会包含文档编号

|   单词   | 文档ID（包含文档编号） |
| :------: | :--------------------: |
| 搜索引擎 |     【1,1】【3,1】     |



- 包含单词出现位置

|   单词   | 文档ID（包含文档编号、单词位置） |
| :------: | :------------------------------: |
| 搜索引擎 |      【1,1,<6>】【3,1,<0>】      |



## 文本搜索过程

![image-20221101114420337](G:\data\LNMRP\$Image\ElasticSearch\es_lucene_match.png)



## 应用场景

- 插入编辑文档时，对文档分析
- 查询时，对查询文本分析



## analyzer过滤器



## 测试分词效果

```json
POST _analyze
{
  "analyzer": "standard", ##分词器
  "text": "hello word"    ##测试文本
}

POST _analyze
{
  "analyzer": "standard",
  "text": "你好呀世界，我来自美丽中国"
}

POST _analyze
{
  "analyzer": "standard",
  "text": "If our time is usefully employed, it will either turn out some useful and important piece of work which will fetch its price in the market, or it will add to our experience and increase our capacities so as to enable us to earn money when the proper opportunity comes. Let those, who think nothing of wasting time, remember this."
}
```



自带分词器

Standard：默认的分词器，按词切分、支持多语言（中文被切分为单个汉字），小写处理。

Simple：非字母切分，小写处理。

Whitespace：空格切分。

Stop：指语气助词等修饰性的词语，the、an

Keyword：不分词。



```json
POST _analyze
{
  "analyzer": "simple",
  "text": "Hello Word 1"
}

POST _analyze
{
  "analyzer": "whitespace",
  "text": "Hello Word 1 啊"
}
```



中文分词器

IK



查看索引的分词器类型



设置分词器



明确字段是否需要分词，不需要分词的字段就将 type 设置为 keyword，可以节省空间和提高写性能。





## 资料

[Lucene 倒排索引原理](https://zhuanlan.zhihu.com/p/395787179)

[进阶学·ES-04-01 analyzer简介](https://www.bilibili.com/video/BV1SV4y1L77u/?spm_id_from=333.999.0.0&vd_source=52fc18888d1edf4ef2b4a3b4f27e09d6)

[Elasticsearch 篇之倒排索引与分词](https://blog.csdn.net/qq_39337886/article/details/103857934)

[官方文档](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-analyzers.html)